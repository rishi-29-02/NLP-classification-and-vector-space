{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "English_French_Translation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW6D2C0b9YQr"
      },
      "source": [
        "# Natural Language Processing with classification and vector spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H36vZH_S94Ex"
      },
      "source": [
        "# Machine Translation System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSO4xpq8-Jv9"
      },
      "source": [
        "# English to French words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXwcDGcJ-OMI"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVwPIziw_dJe"
      },
      "source": [
        "The data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jleho6zr-xDT"
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lo043s0-UiP"
      },
      "source": [
        "en_embeddings = pickle.load(open('en_embeddings.p', 'rb'))\n",
        "fr_embeddings = pickle.load(open('fr_embeddings.p', 'rb'))"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_h1Mgqj_VUV"
      },
      "source": [
        "Load two dictionaries mapping the english and frech words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c347DPgy_sIA"
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6faY1tYsDM94"
      },
      "source": [
        "Build a function that returns the english to french dictionary given a file where the each column corresponds to a word.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKJKA95nFPIw"
      },
      "source": [
        "If there will be repitition of the words then we will consider the final mapping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go7JCqdEAD6r"
      },
      "source": [
        "def get_dict(file_name):\n",
        "    my_file = pd.read_csv(file_name, delimiter=' ')\n",
        "    etof = {}  # the english to french dictionary to be returned\n",
        "    for i in range(len(my_file)):\n",
        "        en = my_file.loc[i][0]\n",
        "        fr = my_file.loc[i][1]\n",
        "        etof[en] = fr\n",
        "  \n",
        "    return etof"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6AbJ0rAEWl7"
      },
      "source": [
        "en_fr_train = get_dict('en-fr.train.txt')\n",
        "en_fr_test = get_dict('en-fr.test.txt')"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM2NQ9nZFAMB",
        "outputId": "d4dc9a77-a3e8-4a8f-dffc-c19a9d0790c0"
      },
      "source": [
        "print('The lenght of the English to French translation training dictionay : ', len(en_fr_train))\n",
        "print('The lenght of the English to French translation testing dictionay : ', len(en_fr_test))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The lenght of the English to French translation training dictionay :  5000\n",
            "The lenght of the English to French translation testing dictionay :  1500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9gFS2TMFskU"
      },
      "source": [
        "Thus the training set is of 5000 words and the test set of 1500 words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlF69k-pGWWL"
      },
      "source": [
        "**Generate embeddings and the transformation matrices**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kQKDLlCGvVG"
      },
      "source": [
        "We will now implement a function get_matrices, which takes the loaded data and returns matrices X and Y."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ9eY51hISk2"
      },
      "source": [
        "def get_matrices(en_fr, fr_vectors, en_vectors):\n",
        "  # create a list for X and Y\n",
        "  X_l = list()\n",
        "  y_l = list()\n",
        "\n",
        "  # get the english words and store them into the set\n",
        "  eng_set = en_vectors.keys()\n",
        "\n",
        "  # get the french words and store them into the set\n",
        "  fr_set = fr_vectors.keys()\n",
        "\n",
        "  for en_word, fr_word in en_fr.items():\n",
        "    if fr_word in fr_set and en_word in eng_set :\n",
        "      en_vec = en_vectors[en_word]\n",
        "      fr_vec = fr_vectors[fr_word]\n",
        "\n",
        "      # append\n",
        "      X_l.append(en_vec)\n",
        "      y_l.append(fr_vec)\n",
        "\n",
        "  X = np.vstack(X_l)\n",
        "  Y = np.vstack(y_l)\n",
        "  return X, Y"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nX1DyrhGSm3l"
      },
      "source": [
        "Now we will use function get_matrices() to obtain sets X_train and Y_train of English and French word embeddings into the corresponding vector space models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIOXdnChStuq"
      },
      "source": [
        "X_train, Y_train = get_matrices(en_fr_train, fr_embeddings, en_embeddings)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxxCIqGuS3tr"
      },
      "source": [
        "**Implementing the Machine Translation Mechanism**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyPy1L1XUrZk"
      },
      "source": [
        "Computing the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlmuBIRWVuf_"
      },
      "source": [
        "def compute_loss(X, Y, R):\n",
        "\n",
        "  m = X.shape[0]\n",
        "\n",
        "  diff = np.dot(X, R) - Y\n",
        "\n",
        "  diff_squared = diff**2\n",
        "\n",
        "  sum_diff_squared = np.sum(diff_squared)\n",
        "\n",
        "  loss = sum_diff_squared/m\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U17N035IWRKX"
      },
      "source": [
        "Compute the gradient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5IjswwYXG_w"
      },
      "source": [
        "def compute_gradient(X, Y, R):\n",
        "\n",
        "  m = X.shape[0]\n",
        "  gradient = (2*np.dot(X.T, (np.dot(X, R) - Y)))/m\n",
        "  \n",
        "  return gradient"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFhkWMlHXjc3"
      },
      "source": [
        "The Gradient Descent Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF488tTWYHA4"
      },
      "source": [
        "def align_embeddings(X, Y, training_steps=100, learning_rate = 0.0003):\n",
        "  np.random.seed(129)\n",
        "  R = np.random.rand(X.shape[1], X.shape[1])\n",
        "\n",
        "  for i in range(training_steps):\n",
        "    if i%25 == 0:\n",
        "      print(f\"loss at iteration {i} is: {compute_loss(X, Y, R):.4f}\")\n",
        "    gradient = compute_gradient(X, Y, R)\n",
        "    R = R- learning_rate*gradient\n",
        "  \n",
        "  return R"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dukd9rqtauhF",
        "outputId": "a16e86ae-bd02-40b1-fe95-830266920436"
      },
      "source": [
        "np.random.seed(129)\n",
        "X = np.random.rand(10, 5)\n",
        "Y = np.random.rand(10, 5)*.1\n",
        "R=align_embeddings(X, Y)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss at iteration 0 is: 3.7242\n",
            "loss at iteration 25 is: 3.6283\n",
            "loss at iteration 50 is: 3.5350\n",
            "loss at iteration 75 is: 3.4442\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLD9Ljsebp5v"
      },
      "source": [
        "**Calculate the transformation matrix R**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1WbHaPlduCb",
        "outputId": "56c6fa03-6069-4284-ac68-5217f73adcc6"
      },
      "source": [
        "R_train = align_embeddings(X_train, Y_train, training_steps=400, learning_rate=0.8)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss at iteration 0 is: 963.0146\n",
            "loss at iteration 25 is: 97.8292\n",
            "loss at iteration 50 is: 26.8329\n",
            "loss at iteration 75 is: 9.7893\n",
            "loss at iteration 100 is: 4.3776\n",
            "loss at iteration 125 is: 2.3281\n",
            "loss at iteration 150 is: 1.4480\n",
            "loss at iteration 175 is: 1.0338\n",
            "loss at iteration 200 is: 0.8251\n",
            "loss at iteration 225 is: 0.7145\n",
            "loss at iteration 250 is: 0.6534\n",
            "loss at iteration 275 is: 0.6185\n",
            "loss at iteration 300 is: 0.5981\n",
            "loss at iteration 325 is: 0.5858\n",
            "loss at iteration 350 is: 0.5782\n",
            "loss at iteration 375 is: 0.5735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBS105Rfd2PV"
      },
      "source": [
        "**Search for the nearest neighbours**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJkOyyxXgof6"
      },
      "source": [
        "def cosine_similarity(A, B):\n",
        "  num = np.dot(A, B)\n",
        "  den = np.linalg.norm(A) * np.linalg.norm(B)\n",
        "  return num/den"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m8fcvv8gHUS"
      },
      "source": [
        "def nearest_neighbor(v, candidates, k=1):\n",
        "  similarity_l = []\n",
        "  for vec in candidates:\n",
        "    sim = cosine_similarity(v, vec)\n",
        "    similarity_l.append(sim)\n",
        "  \n",
        "  sorted_ids = np.argsort(similarity_l)\n",
        "  k_idx = sorted_ids[-k:]\n",
        "\n",
        "  return k_idx"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ot_zFVchjAt",
        "outputId": "44ae70bc-5a2d-4835-b6fe-61ef80984eaf"
      },
      "source": [
        "# Test your implementation:\n",
        "v = np.array([1, 0, 1])\n",
        "candidates = np.array([[1, 0, 5], [-2, 5, 3], [2, 0, 1], [6, -9, 5], [9, 9, 9]])\n",
        "print(candidates[nearest_neighbor(v, candidates, 3)])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9 9 9]\n",
            " [1 0 5]\n",
            " [2 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0ODaqiQurwc"
      },
      "source": [
        "v1 = np.array"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnJCxfQChnLJ"
      },
      "source": [
        "**Test our function and determine the accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f7lE_ZKinkK"
      },
      "source": [
        "def test_vocabulary(X, Y, R):\n",
        " \n",
        "  pred = np.dot(X, R)\n",
        "  num_corrects = 0\n",
        "\n",
        "  for i in range(len(pred)):\n",
        "    pred_idx = nearest_neighbor(pred[i], Y)\n",
        "\n",
        "    if pred_idx == i:\n",
        "      num_corrects+=1\n",
        "\n",
        "  accuracy = num_corrects/len(pred)\n",
        "  return accuracy"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVbAK8xrjtJl"
      },
      "source": [
        "X_val, Y_val = get_matrices(en_fr_test, fr_embeddings, en_embeddings)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqEznIaCkNdv",
        "outputId": "39b6418a-d5e1-445f-975d-e88b00cf87c0"
      },
      "source": [
        "acc = test_vocabulary(X_val, Y_val, R_train)  # this might take a minute or two\n",
        "print(f\"accuracy on test set is {acc:.3f}\")"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on test set is 0.557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmzKU1mp1Nb3"
      },
      "source": [
        "**Test for few words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZCbuWmslpaQ"
      },
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVv0OdY0ojNp"
      },
      "source": [
        "def get_eng(file_name):\n",
        "    my_file = pd.read_csv(file_name, delimiter=',')\n",
        "    eng_words = []  # the english to french dictionary to be returned\n",
        "    for i in range(len(my_file)):\n",
        "      eng_words.append(my_file.loc[i][0])   \n",
        "  \n",
        "    return eng_words"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OADXlQP7m51i",
        "outputId": "a53054a8-5a81-46b2-f666-bdafa8e235ce"
      },
      "source": [
        "en_fr_demo = get_eng('en_fr_demo2.csv')\n",
        "en_fr_demo"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tools', 'dog']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C5IWEYOtTiB"
      },
      "source": [
        "def get_vec(en_fr_demo, en_vectors):\n",
        "  X_l = list()\n",
        "\n",
        "  eng_words = en_vectors.keys()\n",
        "\n",
        "  for en_word in en_fr_demo:\n",
        "    if en_word in eng_words:\n",
        "      en_vec = en_vectors[en_word]\n",
        "      X_l.append(en_vec)\n",
        "  X = np.vstack(X_l) \n",
        "  return X"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBRLsbOPt8Rt",
        "outputId": "c6620f6f-10c5-4a05-a7d5-5057d747a45e"
      },
      "source": [
        "X_demo = get_vec(en_fr_demo, en_embeddings)\n",
        "X_demo.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk7NoAqbyRtX"
      },
      "source": [
        "def get_key(val):\n",
        "  for key, value in fr_embeddings.items():\n",
        "    if (val == value).all():\n",
        "      return key"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGTsB_6Xw9Ko",
        "outputId": "c4a155e4-4141-4264-de48-3ee287a3d29f"
      },
      "source": [
        "for i in range(len(en_fr_demo)):\n",
        "  pred = np.dot(X_demo[i], R_train)\n",
        "  match_word_vec = Y_train[nearest_neighbor(pred, Y_train)]\n",
        "  word = get_key(match_word_vec)\n",
        "  print(en_fr_demo[i], word)  "
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tools outils\n",
            "dog chien\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImAJiQSXhDDz"
      },
      "source": [
        "Thus our model performs pretty well."
      ]
    }
  ]
}