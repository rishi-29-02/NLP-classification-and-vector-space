{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis Naive Bayes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mwANO9zjHMj"
      },
      "source": [
        "# Natural Language Processing with classification and vector spaces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7iB1gZvkNiH"
      },
      "source": [
        "# Sentiment Analysis using Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ycSIESkSuT"
      },
      "source": [
        "Import Libraries and functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMKOdvAxlVgF"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import twitter_samples\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO3DozPMlvqj",
        "outputId": "9ff30513-9acf-4b54-e402-54f7a2b97bd2"
      },
      "source": [
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHvN__Dglzox",
        "outputId": "7fb7951a-0a90-4e24-bfa0-630a1fec1559"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYvphf88mKUA"
      },
      "source": [
        "Get the sets of positive and negative tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GstmLFsMl3qW"
      },
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwAp60VTmX-7"
      },
      "source": [
        "Get some raw tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfk1sqKhmcnX"
      },
      "source": [
        "np.random.seed(1)\n",
        "rand = np.random.randint(0, 5000, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cBmaUEAmmUF",
        "outputId": "45dd4858-1fb8-4638-af2a-1a9c1196cd20"
      },
      "source": [
        "print('Positive Tweets ::')\n",
        "print('\\033[92m')\n",
        "for i in rand:\n",
        "  print(all_positive_tweets[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Tweets ::\n",
            "\u001b[92m\n",
            "@ZarlashtFaisal @Tabinda_Samar Sethi was HIGH ??? :)\n",
            "Fav if awake fam :)\n",
            "Just smile even your in Pain :) http://t.co/AxTiqf0xek\n",
            "camillus pleaseee? :)\n",
            "Why have i just painted my nails pink :) ???\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymk1Ew8inLLq",
        "outputId": "904f4d81-c68b-4149-88e4-3d4fbd861ead"
      },
      "source": [
        "print('Negative Tweets ::')\n",
        "print('\\033[91m')\n",
        "for i in rand:\n",
        "  print(all_negative_tweets[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative Tweets ::\n",
            "\u001b[91m\n",
            "I need a big cuddle from Lew and kisses on my face :(((( I don't want to go through this again\n",
            "@kaiality too late now :(\n",
            "traffic :-(\n",
            "Soft defence by the best defensive team there :( #NRLTigersRoosters\n",
            "@LukeBryanOnline Yayyyy!!! I hope it's not while I am knocked out by anesthesia. I will be so sad if I miss it :(\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv0oSgWSzC4z"
      },
      "source": [
        "##Implementing the helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF-xhQpJngm7"
      },
      "source": [
        "**Process tweet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihy-D4fin_U9"
      },
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def process_tweet(tweet):\n",
        "  stemmer = PorterStemmer() \n",
        "  stopwords_english = stopwords.words('english')\n",
        "\n",
        "  # remove the stock market tickers\n",
        "  tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "\n",
        "  # remove the old styles retweet text 'RT'\n",
        "  tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "\n",
        "  # remove the hyperlinks\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "\n",
        "  # remove the # symbol\n",
        "  tweet = re.sub(r'#', '', tweet)\n",
        "\n",
        "  # Tokenize the tweet\n",
        "  tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
        "  tweet_tokens = tokenizer.tokenize(tweet)\n",
        "\n",
        "  tweet_clean = []\n",
        "\n",
        "  # removing stopwords and punctuation\n",
        "  for word in tweet_tokens:\n",
        "    if (word not in stopwords_english and\n",
        "        word not in string.punctuation):\n",
        "      stem_word = stemmer.stem(word)    #stemming\n",
        "      tweet_clean.append(stem_word)\n",
        "\n",
        "  return tweet_clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZOQ0GuYsc9L"
      },
      "source": [
        "Let's see how process_tweet performs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHBInC97rS2C",
        "outputId": "ec56dd75-303f-480e-eac9-4ad0944a8898"
      },
      "source": [
        "tweet = all_positive_tweets[np.random.randint(0, 5000)]\n",
        "print('Raw tweet : \\n', tweet)\n",
        "tweet = process_tweet(tweet)\n",
        "print('After processing the tweet : \\n', tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw tweet : \n",
            " @WforWoman 5. Over 20 W kurtas! And my Mom has about half the number I have :D #WSaleLove\n",
            "After processing the tweet : \n",
            " ['5', '20', 'w', 'kurta', 'mom', 'half', 'number', ':D', 'wsalelov']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IngR_nqrshRn"
      },
      "source": [
        "**Count tweets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_KOfDxJwj1J"
      },
      "source": [
        "def count_tweets(tweets, ys):\n",
        "  ys_list = np.squeeze(ys).tolist()\n",
        "  freqs ={}\n",
        "\n",
        "  for y, tweet in zip(ys_list, tweets):\n",
        "    for word in process_tweet(tweet):\n",
        "      pair = (word, y)\n",
        "      if pair in freqs:\n",
        "        freqs[pair] +=1\n",
        "      else:\n",
        "        freqs[pair] = 1\n",
        "  \n",
        "  return freqs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9uYeIQE9Lsk"
      },
      "source": [
        "**Lookup**\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEpMGP_19RBC"
      },
      "source": [
        "# A function to return the frequency of positive and negative frequencies for the specific words\n",
        "def lookup(freqs, word, label):\n",
        "  n = 0\n",
        "  pair = (word, label)\n",
        "  if pair in freqs:\n",
        "    n = freqs[pair]\n",
        "  return n "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhjM_w0exthA"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3e6e1HVzsXF"
      },
      "source": [
        "# splitting the data for training and testing \n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "# numpy array for the labels in the training set\n",
        "train_y = np.append(np.ones((len(train_pos))), np.zeros((len(train_neg))))\n",
        "test_y = np.append(np.ones((len(test_neg))), np.zeros((len(test_neg))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RObIM5ED1sZQ"
      },
      "source": [
        "## Train the model using Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwjiW6_-1ymW"
      },
      "source": [
        "# Build a frequency dictionary\n",
        "freqs = count_tweets(train_x, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHHvfyJ18s_h"
      },
      "source": [
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "  logliklihood = {}\n",
        "  logprior = 0\n",
        "\n",
        "  # calculate V, number of unique words in the vocabulary\n",
        "  vocab = set([pair[0] for pair in freqs.keys()])\n",
        "  V = len(vocab)\n",
        "\n",
        "  ## Calculate N_pos, N_neg, V_pos, V_neg\n",
        "  # N_pos : total number of positive words\n",
        "  # N_neg : total number of negative words\n",
        "  # V_pos : total number of unique positive words\n",
        "  # V_neg : total number of unique negative words\n",
        "\n",
        "  N_pos = N_neg = V_pos = V_neg = 0\n",
        "  for pair in freqs.keys():\n",
        "    if pair[1]>0:\n",
        "      V_pos +=1\n",
        "      N_pos += freqs[pair]\n",
        "    else:\n",
        "      V_neg +=1\n",
        "      N_neg += freqs[pair]\n",
        "\n",
        "  # Number of Documents (tweets)\n",
        "  D = len(train_y)\n",
        "\n",
        "  # D_pos, number of positive documnets\n",
        "  D_pos = len(list(filter(lambda x: x>0, train_y)))\n",
        "\n",
        "  # D_pos, number of negative documnets\n",
        "  D_neg = len(list(filter(lambda x: x<=0, train_y)))\n",
        "\n",
        "  # calculate the logprior\n",
        "  logprior = np.log(D_pos) - np.log(D_neg)\n",
        "\n",
        "  for word in vocab:\n",
        "    freqs_pos = lookup(freqs, word, 1)\n",
        "    freqs_neg = lookup(freqs, word, 0)\n",
        "\n",
        "    # calculte the probability of each word being positive and negative\n",
        "    p_w_pos = (freqs_pos+1)/(N_pos+V)\n",
        "    p_w_neg = (freqs_neg+1)/(N_neg+V)\n",
        "\n",
        "    logliklihood[word] = np.log(p_w_pos/p_w_neg)\n",
        "  \n",
        "  return logprior, logliklihood"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48TXGaCjFZE1",
        "outputId": "8c86a0bc-dc46-4da3-aade-b1543874f8ff"
      },
      "source": [
        "logprior, loglikelihood = train_naive_bayes(freqs, train_x, train_y)\n",
        "print(logprior)\n",
        "print(len(loglikelihood))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "9089\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkz8JImUFhdw"
      },
      "source": [
        "## Test the model naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsAvyaHXG0bI"
      },
      "source": [
        "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
        "  word_l = process_tweet(tweet)\n",
        "  p = 0\n",
        "  p+=logprior\n",
        "\n",
        "  for word in word_l:\n",
        "    if word in loglikelihood:\n",
        "      p+=loglikelihood[word]\n",
        "\n",
        "  return p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHn8HkbCIVqs"
      },
      "source": [
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "  accuracy = 0\n",
        "  y_hats = []\n",
        "  for tweet in test_x:\n",
        "    if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
        "      y_hat_i = 1\n",
        "    else:\n",
        "      y_hat_i = 0\n",
        "    y_hats.append(y_hat_i)\n",
        "  error = np.mean(np.absolute(test_y - y_hats))\n",
        "  accuracy = 1-error\n",
        "\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VK-yPotvKShY",
        "outputId": "ff7b6945-d212-4d52-e344-c9684f7ed047"
      },
      "source": [
        "print(\"Naive Bayes accuracy = %0.4f\" %\n",
        "      (test_naive_bayes(test_x, test_y, logprior, loglikelihood)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes accuracy = 0.9940\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBLmDuIjOwd6"
      },
      "source": [
        "## Check the model on our own tweets "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhxI7F0-KifB",
        "outputId": "301bb629-2c97-4c05-dc30-bbd285e57f6a"
      },
      "source": [
        "tweets = ['I am happy', 'I am bad', 'this movie should have been great.', 'great', 'great great',\n",
        "          'great great great', 'great great great great', 'I am not happy :(']\n",
        "for tweet in tweets:\n",
        "    p = naive_bayes_predict(tweet, logprior, loglikelihood)\n",
        "    if p>1:\n",
        "      print('\\033[92m')\n",
        "      print(f'{tweet} :: Positive sentiment ({p:.2f})')\n",
        "    else:\n",
        "      print('\\033[91m')\n",
        "      print(f'{tweet} :: Negative Sentiment ({p:.2f})')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[92m\n",
            "I am happy :: Positive sentiment (2.15)\n",
            "\u001b[91m\n",
            "I am bad :: Negative Sentiment (-1.29)\n",
            "\u001b[92m\n",
            "this movie should have been great. :: Positive sentiment (2.14)\n",
            "\u001b[92m\n",
            "great :: Positive sentiment (2.14)\n",
            "\u001b[92m\n",
            "great great :: Positive sentiment (4.28)\n",
            "\u001b[92m\n",
            "great great great :: Positive sentiment (6.41)\n",
            "\u001b[92m\n",
            "great great great great :: Positive sentiment (8.55)\n",
            "\u001b[91m\n",
            "I am not happy :( :: Negative Sentiment (-5.36)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}